"""
AIæ‰¹é‡å¤„ç†å™¨ - ä¸€æ¬¡æ€§ç­›é€‰å’Œåˆ†ææ‰€æœ‰æ–°é—»
æ€§èƒ½ä¼˜åŒ–ç‰ˆï¼š1æ¬¡APIè°ƒç”¨ä»£æ›¿158æ¬¡
"""

import asyncio
import json
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
from dataclasses import dataclass, field

from fastapi_poe import get_bot_response

from src.learning.explicit_feedback import ExplicitFeedbackManager, FewShotExample

logger = logging.getLogger(__name__)


@dataclass
class ProcessedItem:
    """å¤„ç†åçš„æ¡ç›®"""
    source: str
    title: str
    url: str
    published_date: datetime
    summary: str
    relevance_score: int
    category: str
    why_matters: str
    impact_analysis: str
    headline_priority: int = 0
    actionable: bool = False
    personal_priority: int = 5
    project_relevance: Dict[str, int] = field(default_factory=dict)
    why_matters_to_you: str = ""
    related_projects: List[str] = field(default_factory=list)
    priority: int = 5
    deep_dive_recommended: bool = False
    deep_dive_reason: str = ""
    article_type: str = "general"


class AIProcessorBatch:
    """æ‰¹é‡AIå¤„ç†å™¨"""
    
    def __init__(
        self,
        api_key: str = None,
        model_name: str = "Claude-Sonnet-4.5",
        user_profile: Dict = None,
        explicit_feedback_manager: Optional[ExplicitFeedbackManager] = None,
    ):
        """
        åˆå§‹åŒ–æ‰¹é‡å¤„ç†å™¨
        
        Args:
            api_key: Poe APIå¯†é’¥
            model_name: æ¨¡å‹åç§°
            user_profile: ç”¨æˆ·é…ç½®
        """
        import os
        self.api_key = api_key or os.getenv('POE_API_KEY')
        self.model_name = model_name
        self.user_profile = user_profile or {}
        self.explicit_feedback_manager = explicit_feedback_manager
        
        if not self.api_key:
            raise ValueError("éœ€è¦è®¾ç½®POE_API_KEYç¯å¢ƒå˜é‡")
    
    def batch_select_and_analyze(
        self, 
        all_items: List[Dict], 
        top_n: int = 25
    ) -> List[ProcessedItem]:
        """
        ä¸€æ¬¡æ€§ç­›é€‰å’Œåˆ†ææ‰€æœ‰æ¡ç›®
        
        Args:
            all_items: æ‰€æœ‰é‡‡é›†çš„æ¡ç›®
            top_n: ç­›é€‰å‡ºçš„æ•°é‡
            
        Returns:
            å¤„ç†åçš„æ¡ç›®åˆ—è¡¨
        """
        logger.info(f"ğŸš€ æ‰¹é‡å¤„ç†æ¨¡å¼å¯åŠ¨: {len(all_items)} æ¡æ–°é—» â†’ ç­›é€‰ Top {top_n}")
        
        # æ„å»ºæ–°é—»åˆ—è¡¨ï¼ˆç®€åŒ–ç‰ˆï¼Œåªå‘é€æ ‡é¢˜å’Œæ‘˜è¦ï¼‰
        news_list = []
        for i, item in enumerate(all_items, 1):
            # å…¼å®¹dataclasså’Œdictï¼Œæ™ºèƒ½æå–æ¥æº
            source = getattr(item, 'source', item.get('source', '') if hasattr(item, 'get') else '')
            
            # å¦‚æœsourceä¸ºç©ºï¼Œå°è¯•ä»repo_nameæˆ–å…¶ä»–å­—æ®µæå–
            if not source or source == 'Unknown':
                # GitHub Releaseé€šå¸¸æœ‰repo_name
                repo_name = getattr(item, 'repo_name', item.get('repo_name', '') if hasattr(item, 'get') else '')
                if repo_name:
                    source = repo_name
                else:
                    source = 'Unknown'
            
            title = getattr(item, 'title', item.get('title', '') if hasattr(item, 'get') else '')[:200]
            
            # ä¼˜å…ˆä½¿ç”¨summaryï¼Œæ²¡æœ‰åˆ™ç”¨description
            if hasattr(item, 'summary'):
                summary = getattr(item, 'summary', '')
            elif hasattr(item, 'description'):
                summary = getattr(item, 'description', '')
            elif hasattr(item, 'get'):
                summary = item.get('summary', item.get('description', ''))
            else:
                summary = ''
            summary = summary[:400]
            
            # å‘å¸ƒæ—¥æœŸ
            pub_date = getattr(item, 'published_date', item.get('published_date', '') if hasattr(item, 'get') else '')
            if isinstance(pub_date, datetime):
                pub_date = pub_date.strftime('%Y-%m-%d')
            
            news_list.append(f"{i}. [{source}] {title}\n   {summary}\n   å‘å¸ƒ: {pub_date}\n")
        
        # æ„å»ºprompt
        user_context = self._build_user_context()
        active_projects = self.user_profile.get('active_projects', [])
        project_names = [proj.get('name') for proj in active_projects if proj.get('name')]
        project_instruction = ""
        if project_names:
            bullet_lines = "\n".join([f"  - {name}" for name in project_names])
            project_instruction = (
                "\né¡¹ç›®ç›¸å…³æ€§è¦æ±‚ï¼š\n"
                "- é’ˆå¯¹ä»¥ä¸‹é¡¹ç›®åˆ†åˆ«ç»™å‡º0-10çš„æ•´æ•°è¯„åˆ†ï¼ˆ0=æ— å…³ï¼Œ10=éœ€è¦ç«‹å³é‡‡å–è¡ŒåŠ¨ï¼‰ï¼š\n"
                f"{bullet_lines}\n"
                "- JSONå­—æ®µ`project_relevance`å¿…é¡»åŒ…å«ä¸Šè¿°æ¯ä¸ªé¡¹ç›®åç§°ä½œä¸ºé”®ã€‚\n"
            )

        few_shot_block = self._build_few_shot_block(news_list)

        prompt = f"""ä½ æ˜¯AIå·¥ç¨‹å¸ˆçš„æŠ€æœ¯åŠ©ç†ã€‚æˆ‘é‡‡é›†äº†{len(all_items)}æ¡AIç›¸å…³æ–°é—»ã€‚

{user_context}{project_instruction}{few_shot_block}

è¯·ç­›é€‰æœ€é‡è¦çš„{top_n}æ¡å¹¶è¯¦ç»†åˆ†æã€‚

æ‰€æœ‰æ–°é—»ï¼š
{''.join(news_list)}

è¿”å›JSONæ•°ç»„ï¼Œæ¯æ¡æ–°é—»åŒ…å«ï¼š
[
  {{
    "index": ç¼–å·(1-{len(all_items)}),
    "summary": "3å¥è¯æ€»ç»“ï¼šç¬¬1å¥æ˜¯ä»€ä¹ˆ(What)ã€ç¬¬2å¥ä¸ºä»€ä¹ˆé‡è¦(Why)ã€ç¬¬3å¥å…·ä½“å˜åŒ–(How)",
    "category": "headline|framework|article|model|project",
    "headline_priority": 0-10,
    "relevance_score": 0-10,
    "why_matters": "ä¸ºä»€ä¹ˆè¿™ä¸ªæ›´æ–°å¯¹ç”¨æˆ·é‡è¦",
    "impact_analysis": "å…·ä½“å½±å“å’Œå»ºè®®è¡ŒåŠ¨",
    "actionable": true|false,
    "personal_priority": 0-10,
    "project_relevance": {{"é¡¹ç›®åç§°": 0-10}},
    "why_matters_to_you": "ç›´æ¥è¯´æ˜å¯¹Davidçš„ä»·å€¼",
    "related_projects": ["ä¸å†…å®¹é«˜åº¦ç›¸å…³çš„é¡¹ç›®åç§°ï¼Œè¯„åˆ†â‰¥6"],
    "deep_dive_recommended": true|false,
    "deep_dive_reason": "å¦‚æœå»ºè®®æ·±å…¥ç ”ç©¶ï¼Œç”¨1å¥è¯è¯´æ˜åŸå› ï¼›å¦åˆ™ç•™ç©º",
    "article_type": "trend|technical|general"
  }}
]

åˆ†ç±»è§„åˆ™ï¼ˆä¸¥æ ¼éµå®ˆï¼‰ï¼š
1. category="headline": å¤´æ¡æ–°é—»/åª’ä½“æŠ¥é“
   - **æ¥è‡ªTechCrunch/VentureBeat/The Verge/MIT Tech Review/Import AIçš„æ–°é—»æŠ¥é“**
   - æ–°æ¨¡å‹å‘å¸ƒã€äº§å“ä¸Šçº¿ã€èèµ„ã€æ”¶è´­ã€é‡å¤§å®•æœºã€è¡Œä¸šæ”¿ç­–
   - å…¬å¸åŠ¨æ€ã€å¸‚åœºåˆ†æã€äº§å“è¯„æµ‹ã€è¡Œä¸šè¶‹åŠ¿æŠ¥é“
   - Hacker Newsçš„çƒ­é—¨è®¨è®ºï¼ˆä½†ä¸åŒ…æ‹¬æ¡†æ¶æ›´æ–°ï¼‰
   - **ä¸¥æ ¼æ’é™¤**ï¼š
     * Towards Data Scienceçš„æ–‡ç« ï¼ˆå¿…é¡»å½’ä¸ºarticleï¼‰
     * GitHub Releaseï¼ˆå¿…é¡»å½’ä¸ºframeworkæˆ–modelï¼‰
     * æ¡†æ¶ç‰ˆæœ¬æ›´æ–°ï¼ˆå¿…é¡»å½’ä¸ºframeworkï¼‰

2. category="framework": æ¡†æ¶/SDKæ›´æ–°
   - **æ‰€æœ‰GitHub Releaseçš„æ¡†æ¶æ›´æ–°**ï¼šLangChain/LlamaIndex/LangGraph/OpenAI Python SDKç­‰
   - ç‰ˆæœ¬å·æ ‡é¢˜ï¼ˆå¦‚v1.0.3, langchain-core==1.0.2ï¼‰å¿…é¡»å½’ä¸ºframework

3. category="article": æ·±åº¦æŠ€æœ¯æ–‡ç« /æ•™ç¨‹/æœ€ä½³å®è·µ
   - **æ‰€æœ‰æ¥è‡ªTowards Data Scienceçš„æ–‡ç« **ï¼ˆæ— è®ºæ ‡é¢˜æ˜¯ä»€ä¹ˆï¼‰
   - æ•™ç¨‹ã€How-toæŒ‡å—ã€æŠ€æœ¯æ·±åº¦åˆ†æ
   - **æ’é™¤**ï¼šæ–°é—»æŠ¥é“

4. category="model": æ–°æ¨¡å‹/æ¨ç†å·¥å…·æ›´æ–°
   - **Ollama/vLLMçš„GitHub Release**ï¼ˆå¦‚v0.12.7ï¼‰
   - æ–°æ¨¡å‹å‘å¸ƒï¼ˆä½†åª’ä½“æŠ¥é“é™¤å¤–ï¼‰

5. category="project": å¼€æºé¡¹ç›®ï¼ˆæ–°å‘å¸ƒçš„AIå·¥å…·ã€åº“ï¼‰
   - Hacker Newsçš„"Show HN"é¡¹ç›®å±•ç¤º

headline_priorityè¯„åˆ†ï¼ˆä»…headlineç±»åˆ«ï¼‰ï¼š
- 10åˆ†ï¼šè¡Œä¸šåœ°éœ‡çº§ï¼ˆGPT-5å‘å¸ƒã€OpenAIè¢«æ”¶è´­ï¼‰
- 8-9åˆ†ï¼šé‡å¤§äº‹ä»¶ï¼ˆé‡è¦äº§å“å‘å¸ƒã€ç‹¬è§’å…½èèµ„ã€æŠ€æœ¯çªç ´ï¼‰
- 6-7åˆ†ï¼šé‡è¦æ–°é—»ï¼ˆäº§å“å‘å¸ƒã€å¤§å‚AIåŠ¨æ€ã€é‡è¦æ”¶è´­ã€å¸‚åœºè¶‹åŠ¿ï¼‰
- 4-5åˆ†ï¼šä¸€èˆ¬æ–°é—»ï¼ˆå°å…¬å¸èèµ„ã€äº§å“æ›´æ–°ã€è¡Œä¸šè§‚å¯Ÿï¼‰
- 2-3åˆ†ï¼šæ™®é€šèµ„è®¯

**åª’ä½“æ¥æºåŠ åˆ†**ï¼šæ¥è‡ªTechCrunch/VentureBeat/The Verge/MIT Tech Reviewçš„æ–°é—»+1åˆ†

ç­›é€‰ç­–ç•¥ï¼ˆéå¸¸é‡è¦ï¼‰ï¼š
1. **ä¼˜å…ˆé€‰æ‹©headlineç±»åˆ«**ï¼ˆåª’ä½“æ–°é—»ã€é‡å¤§äº‹ä»¶ã€äº§å“å‘å¸ƒï¼‰
2. **ä¸¥æ ¼æ’é™¤framework/modelç±»åˆ«**ï¼šGitHub Releaseã€æ¡†æ¶æ›´æ–°ä¸è¦è¿›å…¥Top 25çš„headlineéƒ¨åˆ†
3. **ä¸¥æ ¼æ’é™¤Towards Data Science**ï¼šæ‰€æœ‰Towards Data Scienceæ–‡ç« å¿…é¡»å½’ä¸ºarticleï¼Œä¸è¿›headline
4. å¹³è¡¡ä¸åŒæ¥æºï¼ˆé¿å…å…¨æ˜¯Hacker Newsï¼‰
5. åŒä¸€æ¥æºçš„å¤šä¸ªç‰ˆæœ¬æ›´æ–°åªä¿ç•™æœ€æ–°/æœ€é‡è¦çš„
6. ç¡®ä¿è‡³å°‘æœ‰3-5æ¡æ¥è‡ªTechCrunch/VentureBeat/The Verge/MIT Tech Reviewçš„åª’ä½“æ–°é—»

ä¸ªäººä¼˜å…ˆçº§ä¸é¡¹ç›®ç›¸å…³æ€§è¯„åˆ†æŒ‡å—ï¼š
- personal_priority 10ï¼šç›´æ¥æ¨è¿›ä¼ä¸šAIè½åœ°æˆ–å½“å‰æ´»è·ƒé¡¹ç›®ï¼Œå¿…é¡»ç«‹å³æ‰§è¡Œ
- personal_priority 7-9ï¼šæ˜¾è‘—å¸®åŠ©Davidçš„å­¦ä¹ é‡ç‚¹æˆ–é¡¹ç›®å†³ç­–ï¼Œå»ºè®®æœ¬å‘¨è·Ÿè¿›
- personal_priority 4-6ï¼šæœ‰å¯å‘æ€§ï¼Œé€‚åˆè®°å½•å¾…æŸ¥
- personal_priority 0-3ï¼šçŸ­æœŸå†…ä»·å€¼è¾ƒä½
- project_relevanceï¼šé’ˆå¯¹æ¯ä¸ªé¡¹ç›®ç»™å‡º0-10åˆ†ï¼Œ10è¡¨ç¤ºç«‹åˆ»å¯åº”ç”¨ï¼Œ7-9è¡¨ç¤ºæœ¬å‘¨å¯è¯„ä¼°ï¼Œ4-6è¡¨ç¤ºä¸­é•¿æœŸå¯å‘ï¼Œ0-3è¡¨ç¤ºæ— å…³

æ·±åº¦ç ”ç©¶æ¨èè§„åˆ™ï¼š
- å¦‚æœå†…å®¹æä¾›å¯ç›´æ¥æ‰§è¡Œçš„æŠ€æœ¯æ–¹æ¡ˆã€å®éªŒæ­¥éª¤æˆ–ä»£ç ï¼Œè¯·è®¾ç½® deep_dive_recommended = trueï¼Œå¹¶ç»™å‡ºæ˜ç¡®ç†ç”±
- å¦‚æœä¸ªäººä¼˜å…ˆçº§ >= 9 æˆ–å¯¹ä»»ä¸€æ´»è·ƒé¡¹ç›®å½±å“è¯„åˆ† >= 8ï¼Œä¹Ÿåº”æ¨è deep dive
- å…³æ³¨èƒ½å½¢æˆç­–ç•¥å¯¹æ¯”æˆ–å†²å‡»ç°æœ‰è·¯çº¿çš„æ–°é—»ï¼ˆä¾‹å¦‚ï¼šæ‰˜ç®¡RAG vs è‡ªå»ºRAGï¼‰

article_type åˆ†ç±»ï¼š
- trendï¼šè¡Œä¸šè¶‹åŠ¿ã€è§‚ç‚¹è§£è¯»ã€æˆ˜ç•¥åˆ†æ
- technicalï¼šæŠ€æœ¯å®ç°ã€æ¶æ„æ‹†è§£ã€å«ç¤ºä¾‹ä»£ç çš„æ•™ç¨‹
- generalï¼šå…¶ä»–å†…å®¹

åªè¿”å›JSONæ•°ç»„ï¼Œä¸è¦markdownæ ‡è®°ï¼Œä¸è¦è§£é‡Šã€‚
"""
        
        try:
            # è°ƒç”¨LLM
            logger.info("æ­£åœ¨è°ƒç”¨LLMè¿›è¡Œæ‰¹é‡åˆ†æ...")
            response_text = asyncio.run(self._call_poe_api(prompt))
            
            # è§£æJSON
            logger.info("è§£æLLMå“åº”...")
            cleaned = self._clean_json_response(response_text)
            analyses = json.loads(cleaned)
            
            logger.info(f"âœ“ LLMè¿”å› {len(analyses)} æ¡åˆ†æç»“æœ")
            
            # è½¬æ¢ä¸ºProcessedItem
            processed = []
            for analysis in analyses:
                idx = analysis.get('index', 0) - 1
                if 0 <= idx < len(all_items):
                    original = all_items[idx]
                    
                    # å…¼å®¹dataclasså’Œdictï¼Œæ™ºèƒ½æå–æ¥æº
                    source = getattr(original, 'source', original.get('source', '') if hasattr(original, 'get') else '')
                    
                    # å¦‚æœsourceä¸ºç©ºï¼Œå°è¯•ä»repo_nameæå–
                    if not source or source == 'Unknown':
                        repo_name = getattr(original, 'repo_name', original.get('repo_name', '') if hasattr(original, 'get') else '')
                        if repo_name:
                            source = repo_name
                        else:
                            source = 'Unknown'
                    
                    title = getattr(original, 'title', original.get('title', '') if hasattr(original, 'get') else '')
                    url = getattr(original, 'url', None) or getattr(original, 'link', None)
                    if url is None and hasattr(original, 'get'):
                        url = original.get('url', original.get('link', ''))
                    url = url or ''
                    
                    pub_date = getattr(original, 'published_date', None)
                    if pub_date is None and hasattr(original, 'get'):
                        pub_date = original.get('published_date', datetime.now())
                    pub_date = pub_date or datetime.now()

                    project_relevance = analysis.get('project_relevance', {}) or {}
                    if not isinstance(project_relevance, dict):
                        project_relevance = {}
                    normalized_project_relevance = {}
                    for name, score in project_relevance.items():
                        try:
                            int_score = int(float(score))
                        except (TypeError, ValueError):
                            continue
                        normalized_project_relevance[str(name)] = max(0, min(10, int_score))

                    related_projects = analysis.get('related_projects', []) or []
                    if not isinstance(related_projects, list):
                        related_projects = []
                    if not related_projects and normalized_project_relevance:
                        related_projects = [
                            project_name
                            for project_name, score in normalized_project_relevance.items()
                            if isinstance(score, int) and score >= 6
                        ]

                    personal_priority = analysis.get('personal_priority', analysis.get('relevance_score', 5))
                    try:
                        personal_priority = int(float(personal_priority))
                    except (TypeError, ValueError):
                        personal_priority = 5
                    personal_priority = max(0, min(10, personal_priority))

                    why_matters_to_you = analysis.get('why_matters_to_you') or analysis.get('why_matters', '')
                    
                    processed.append(ProcessedItem(
                        source=source,
                        title=title,
                        url=url,
                        published_date=pub_date,
                        summary=analysis.get('summary', ''),
                        relevance_score=analysis.get('relevance_score', 5),
                        category=analysis.get('category', 'other'),
                        why_matters=analysis.get('why_matters', ''),
                        impact_analysis=analysis.get('impact_analysis', ''),
                        headline_priority=analysis.get('headline_priority', 0),
                        actionable=analysis.get('actionable', False),
                        personal_priority=personal_priority,
                        project_relevance=normalized_project_relevance,
                        why_matters_to_you=why_matters_to_you,
                        related_projects=related_projects,
                        priority=personal_priority,
                        deep_dive_recommended=bool(analysis.get('deep_dive_recommended', False)),
                        deep_dive_reason=analysis.get('deep_dive_reason', ''),
                        article_type=analysis.get('article_type', 'general')
                    ))
                else:
                    logger.warning(f"ç´¢å¼•è¶…å‡ºèŒƒå›´: {idx+1}")
            
            # ç»Ÿè®¡åˆ†ç±»åˆ†å¸ƒ
            category_dist = {}
            for item in processed:
                category_dist[item.category] = category_dist.get(item.category, 0) + 1
            
            logger.info(f"âœ“ æ‰¹é‡å¤„ç†å®Œæˆï¼ç­›é€‰å‡º {len(processed)} æ¡")
            logger.info(f"  åˆ†ç±»åˆ†å¸ƒ: {category_dist}")
            
            return processed
            
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æå¤±è´¥: {str(e)}")
            logger.error(f"å“åº”å‰500å­—ç¬¦: {response_text[:500] if response_text else 'None'}")
            raise
        except Exception as e:
            logger.error(f"æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}")
            raise
    
    async def _call_poe_api(self, prompt: str) -> str:
        """
        è°ƒç”¨Poe API
        
        Args:
            prompt: æç¤ºè¯
            
        Returns:
            APIå“åº”æ–‡æœ¬
        """
        try:
            full_response = ""
            async for partial in get_bot_response(
                messages=[{"role": "user", "content": prompt}],
                bot_name=self.model_name,
                api_key=self.api_key
            ):
                full_response += partial.text
            
            return full_response
            
        except Exception as e:
            logger.error(f"Poe APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise
    
    def _clean_json_response(self, response_text: str) -> str:
        """
        æ¸…ç†JSONå“åº”
        
        Args:
            response_text: åŸå§‹å“åº”
            
        Returns:
            æ¸…ç†åçš„JSONå­—ç¬¦ä¸²
        """
        if not response_text:
            raise ValueError("å“åº”ä¸ºç©º")
        
        # å»é™¤ç©ºç™½
        cleaned = response_text.strip()
        
        # å»é™¤markdownä»£ç å—æ ‡è®°
        cleaned = cleaned.replace('```json\n', '').replace('```json', '')
        cleaned = cleaned.replace('\n```', '').replace('```', '')
        cleaned = cleaned.strip()
        
        # å¦‚æœä¸æ˜¯ä»¥[æˆ–{å¼€å¤´ï¼Œå°è¯•æå–JSON
        if not cleaned.startswith('[') and not cleaned.startswith('{'):
            # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª[æˆ–{
            start_bracket = cleaned.find('[')
            start_brace = cleaned.find('{')
            
            start = -1
            if start_bracket != -1 and start_brace != -1:
                start = min(start_bracket, start_brace)
            elif start_bracket != -1:
                start = start_bracket
            elif start_brace != -1:
                start = start_brace
            
            if start != -1:
                # æŸ¥æ‰¾å¯¹åº”çš„ç»“æŸç¬¦
                if cleaned[start] == '[':
                    end = cleaned.rfind(']') + 1
                else:
                    end = cleaned.rfind('}') + 1
                
                if end > start:
                    cleaned = cleaned[start:end]
        
        return cleaned
    
    def _build_user_context(self) -> str:
        """æ„å»ºç”¨æˆ·ä¸Šä¸‹æ–‡æè¿°"""
        if not self.user_profile:
            return """ç”¨æˆ·èƒŒæ™¯ï¼š
- è§’è‰²ï¼šBackend Developer â†’ AI Engineer
- ç»éªŒï¼š20+ years backend development
- èŒä¸šç›®æ ‡ï¼šåœ¨ä¼ä¸šå†…éƒ¨è½åœ°AIåº”ç”¨
- æ´»è·ƒé¡¹ç›®ï¼šmutation-test-killer, ai-digest, rag-practics
"""
        
        user_info = self.user_profile.get('user_info', {})
        career_goals = self.user_profile.get('career_goals', {})
        active_projects = self.user_profile.get('active_projects', [])
        learning_focus = self.user_profile.get('learning_focus', {})
        relevance_criteria = self.user_profile.get('relevance_criteria', {})
        secondary_goals = career_goals.get('secondary', [])
        project_lines = []
        for idx, project in enumerate(active_projects, start=1):
            name = project.get('name', f"é¡¹ç›®{idx}")
            description = project.get('description', '')
            goals = ", ".join(project.get('goals', []))
            tech_stack = ", ".join(project.get('tech_stack', []))
            lines = [f"{idx}. {name}ï¼š{description}"]
            if goals:
                lines.append(f"   ç›®æ ‡ï¼š{goals}")
            if tech_stack:
                lines.append(f"   æŠ€æœ¯æ ˆï¼š{tech_stack}")
            project_lines.append("\n".join(lines))
        projects_block = "\n".join(project_lines) if project_lines else "æš‚æ— æ˜ç¡®é¡¹ç›®"
        current_focus = ", ".join(learning_focus.get('current', [])) or "æŒç»­æ¢ç´¢"
        interested_focus = ", ".join(learning_focus.get('interested_in', [])) or "æŒç»­è¡¥å……"
        high_priority = ", ".join(relevance_criteria.get('high_priority', []))
        medium_priority = ", ".join(relevance_criteria.get('medium_priority', []))
        low_priority = ", ".join(relevance_criteria.get('low_priority', []))
        context = f"""ç”¨æˆ·èƒŒæ™¯ï¼š
- å§“åï¼š{user_info.get('name', 'ç”¨æˆ·')}
- è§’è‰²ï¼š{user_info.get('role', 'Backend Developer â†’ AI Engineer')}
- ç»éªŒï¼š{user_info.get('experience', '20+ years backend development')}
- å½“å‰é˜¶æ®µï¼š{user_info.get('current_stage', 'AIå­¦ä¹ ä¸è½åœ°æ¢ç´¢')}
- èŒä¸šç›®æ ‡ï¼ˆprimaryï¼‰ï¼š{career_goals.get('primary', 'åœ¨ä¼ä¸šå†…éƒ¨è½åœ°AIåº”ç”¨')}
- èŒä¸šç›®æ ‡ï¼ˆsecondaryï¼‰ï¼š{', '.join(secondary_goals) if secondary_goals else 'æŒç»­æ‰©å±•AIèƒ½åŠ›'}

æ´»è·ƒé¡¹ç›®ï¼š
{projects_block}

å­¦ä¹ é‡ç‚¹ï¼š
- å½“å‰å…³æ³¨ï¼š{current_focus}
- æ„Ÿå…´è¶£æ–¹å‘ï¼š{interested_focus}

é«˜ä¼˜å…ˆçº§ä¸»é¢˜ï¼š{high_priority}
ä¸­ä¼˜å…ˆçº§ä¸»é¢˜ï¼š{medium_priority}
ä½ä¼˜å…ˆçº§ä¸»é¢˜ï¼š{low_priority}
"""
        return context

    def _build_few_shot_block(self, news_list: List[str]) -> str:
        if not self.explicit_feedback_manager:
            return ""

        sample_context = "\n".join(news_list[:3])
        examples = self.explicit_feedback_manager.retrieve_similar_corrections(
            sample_context,
            correction_type="batch_selection",
            top_k=2,
        )
        if not examples:
            examples = self.explicit_feedback_manager.get_recent_corrections(
                correction_type="analysis",
                top_k=2,
            )
        if not examples:
            return ""

        lines = ["\nå‚è€ƒç”¨æˆ·ä¿®æ­£ç¤ºä¾‹ï¼ˆè¯·é¿å…é‡å¤é”™è¯¯ï¼‰ï¼š"]
        for idx, example in enumerate(examples, start=1):
            lines.append(f"{idx}. é”™è¯¯è¾“å‡ºï¼š{example.original_output}")
            lines.append(f"   æ­£ç¡®è¾“å‡ºï¼š{example.corrected_output}")
        lines.append("")
        return "\n".join(lines)

