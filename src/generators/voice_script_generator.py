"""
Voice Script Generator
å°†Markdownå‘¨æŠ¥è½¬æ¢ä¸ºé€‚åˆå£æ’­çš„ä¸­æ–‡æ–‡å­—ç¨¿ã€‚
"""

from __future__ import annotations

import logging
import re
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, List, Optional

logger = logging.getLogger(__name__)


@dataclass
class HeadlineItem:
    index: int
    title: str
    source: str
    published: str
    summary: str


@dataclass
class SimpleItem:
    title: str
    source: str
    summary: str


class VoiceScriptGenerator:
    """æ ¹æ®Markdownå‘¨æŠ¥ç”Ÿæˆä¸­æ–‡å£æ’­ç¨¿"""

    def __init__(
        self,
        intro_template: Optional[str] = None,
        outro_template: Optional[str] = None,
    ) -> None:
        self.intro_template = (
            intro_template
            or "å¤§å®¶å¥½ï¼Œè¿™é‡Œæ˜¯{date}çš„AIå·¥ç¨‹å¸ˆå‘¨æŠ¥å£æ’­ç¨¿ã€‚æˆ‘ä»¬å…ˆä»æœ¬å‘¨çš„é‡ç‚¹æ–°é—»å¼€å§‹ã€‚"
        )
        self.outro_template = (
            outro_template
            or "ä»¥ä¸Šå°±æ˜¯æœ¬æœŸAIå·¥ç¨‹å¸ˆå‘¨æŠ¥å£æ’­ç¨¿ã€‚æ„Ÿè°¢æ”¶å¬ï¼Œæˆ‘ä»¬ä¸‹æ¬¡å†è§ã€‚"
        )

        self.heading_pattern = re.compile(r"^(#{2,})\s+(.*)")
        self.headline_pattern = re.compile(r"^####\s+(\d+)\.\s+(.*)")
        self.bold_field_pattern = re.compile(r"^\*\*(.+?)\*\*:\s*(.*)")

    # ------------------------------------------------------------------ #
    def generate(self, markdown_text: str, output_path: str) -> None:
        """æ ¹æ®Markdownå†…å®¹ç”Ÿæˆå£æ’­ç¨¿"""
        try:
            context = self._parse_markdown(markdown_text)
            script = self._build_script(context)
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(script)
            logger.info("âœ“ å£æ’­ç¨¿å·²ç”Ÿæˆ: %s", output_path)
        except Exception as exc:  # pragma: no cover - æ—¥å¿—è®°å½•
            logger.warning("ç”Ÿæˆå£æ’­ç¨¿å¤±è´¥: %s", exc, exc_info=True)

    # ------------------------------------------------------------------ #
    def _build_script(self, context: Dict[str, List]) -> str:
        date_str = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        parts: List[str] = [self.intro_template.format(date=date_str), ""]

        # Top headlines
        headlines: List[HeadlineItem] = context.get("headlines", [])
        if headlines:
            parts.append("æœ¬å‘¨åæ¡é‡ç‚¹å¤´æ¡åˆ†åˆ«æ˜¯ï¼š")
            for item in headlines:
                sentence = (
                    f"ç¬¬{item.index}æ¡å¤´æ¡ï¼Œæ¥è‡ª{item.source}ï¼Œå‘å¸ƒæ—¶é—´ {item.published}ã€‚"
                    f"æ ‡é¢˜ï¼š{item.title}ã€‚"
                    f"æ ¸å¿ƒå†…å®¹ï¼š{item.summary}"
                )
                parts.append(self._normalize_sentence(sentence))
            parts.append("")

        # æ·±åº¦æ´å¯Ÿ
        insights: List[SimpleItem] = context.get("insights", [])
        if insights:
            parts.append("æ¥ä¸‹æ¥æ˜¯æ·±åº¦æ´å¯Ÿä¸æˆ˜æœ¯ç²¾é€‰ï¼š")
            for idx, item in enumerate(insights, 1):
                sentence = (
                    f"ç¬¬{idx}ç¯‡ç²¾é€‰æ–‡ç« ï¼Œæ¥è‡ª{item.source}ï¼Œæ ‡é¢˜ã€Š{item.title}ã€‹ã€‚"
                    f"ä¸»è¦è§‚ç‚¹ï¼š{item.summary}"
                )
                parts.append(self._normalize_sentence(sentence))
            parts.append("")

        # ç²¾é€‰é¡¹ç›®
        projects: List[SimpleItem] = context.get("projects", [])
        if projects:
            parts.append("æœ¬å‘¨å€¼å¾—å…³æ³¨çš„å¼€æºæˆ–ç¤¾åŒºé¡¹ç›®åŒ…æ‹¬ï¼š")
            for idx, item in enumerate(projects, 1):
                sentence = (
                    f"é¡¹ç›®{idx}ï¼š{item.source}å‘å¸ƒçš„ã€Š{item.title}ã€‹ã€‚"
                    f"é¡¹ç›®äº®ç‚¹ï¼š{item.summary}"
                )
                parts.append(self._normalize_sentence(sentence))
            parts.append("")

        # æ¡†æ¶æ›´æ–°
        frameworks: List[SimpleItem] = context.get("frameworks", [])
        if frameworks:
            parts.append("æ¡†æ¶ä¸å·¥å…·æ–¹é¢çš„å…³é”®æ›´æ–°ï¼š")
            for idx, item in enumerate(frameworks, 1):
                sentence = (
                    f"æ›´æ–°{idx}ï¼š{item.source}å‘å¸ƒã€Š{item.title}ã€‹ã€‚"
                    f"æ›´æ–°å†…å®¹ï¼š{item.summary}"
                )
                parts.append(self._normalize_sentence(sentence))
            parts.append("")

        # æ–°æ¨¡å‹
        models: List[SimpleItem] = context.get("models", [])
        if models:
            parts.append("æ–°æ¨¡å‹ä¸å¹³å°çš„åŠ¨æ€ï¼š")
            for idx, item in enumerate(models, 1):
                sentence = (
                    f"æ¨¡å‹{idx}ï¼š{item.source}æ¨å‡ºã€Š{item.title}ã€‹ã€‚"
                    f"æ ¸å¿ƒä¿¡æ¯ï¼š{item.summary}"
                )
                parts.append(self._normalize_sentence(sentence))
            parts.append("")

        # å¸‚åœºæ´å¯Ÿ
        market: List[SimpleItem] = context.get("market", [])
        if market:
            parts.append("æœ€åè¡¥å……å‡ æ¡å¸‚åœºæ´å¯Ÿï¼š")
            for idx, item in enumerate(market, 1):
                sentence = (
                    f"æ´å¯Ÿ{idx}ï¼š{item.source}å‘å¸ƒã€Š{item.title}ã€‹ã€‚"
                    f"è¦ç‚¹ï¼š{item.summary}"
                )
                parts.append(self._normalize_sentence(sentence))
            parts.append("")

        parts.append(self.outro_template)
        script = "\n".join(parts).strip() + "\n"
        return script

    # ------------------------------------------------------------------ #
    def _parse_markdown(self, markdown_text: str) -> Dict[str, List]:
        """å°†Markdownå†…å®¹è§£æä¸ºç»“æ„åŒ–æ•°æ®"""
        lines = markdown_text.splitlines()
        idx = 0
        total = len(lines)

        context: Dict[str, List] = {
            "headlines": [],
            "insights": [],
            "projects": [],
            "frameworks": [],
            "models": [],
            "market": [],
        }

        current_section = None
        while idx < total:
            line = lines[idx].strip()

            # è¯†åˆ« section
            heading_match = self.heading_pattern.match(line)
            if heading_match:
                hashes, title = heading_match.groups()
                level = len(hashes)
                if level == 2:
                    current_section = self._normalize_title(title)
                    idx += 1
                    continue

            # è§£æå¤´æ¡
            if current_section == "æœ¬å‘¨å¤´æ¡":
                headline_match = self.headline_pattern.match(line)
                if headline_match:
                    index = int(headline_match.group(1))
                    title = headline_match.group(2).strip()
                    idx += 1
                    meta = self._collect_metadata(lines, idx)
                    idx = meta["next_index"]
                    summary = meta.get("summary", "")
                    context["headlines"].append(
                        HeadlineItem(
                            index=index,
                            title=title,
                            source=meta.get("source", ""),
                            published=meta.get("published", ""),
                            summary=summary,
                        )
                    )
                    continue

            # è§£æå…¶ä»– section ä¸­çš„æ¡ç›®
            if current_section in (
                "æ·±åº¦æ´å¯Ÿä¸æˆ˜æœ¯ (ç²¾é€‰æŠ€æœ¯æ–‡ç« )",
                "æœ¬å‘¨ç²¾é€‰é¡¹ç›® (OSS Spotlight)",
                "æ¡†æ¶ä¸å·¥å…·æ›´æ–° (Framework & Tooling Corner)",
                "æ–°æ¨¡å‹ä¸å¹³å° (New Models & Platforms)",
                "å¸‚åœºåŠ¨æ€ä¸è¶‹åŠ¿",
            ):
                if line.startswith("#### "):
                    title = line.lstrip("#").strip()
                    idx += 1
                    meta = self._collect_metadata(lines, idx)
                    idx = meta["next_index"]
                    item = SimpleItem(
                        title=title,
                        source=meta.get("source", ""),
                        summary=meta.get("summary", ""),
                    )
                    key = self._section_key(current_section)
                    context[key].append(item)
                    continue

            idx += 1

        return context

    def _collect_metadata(self, lines: List[str], start_index: int) -> Dict[str, str]:
        """æ”¶é›†æ¥æº/å‘å¸ƒæ—¶é—´/æ‘˜è¦ç­‰å­—æ®µ"""
        meta: Dict[str, str] = {}
        idx = start_index
        total = len(lines)
        summary_lines: List[str] = []
        capturing_summary = False

        while idx < total:
            text = lines[idx].strip()

            if text.startswith("---"):
                idx += 1
                break

            if text.startswith("**"):
                match = self.bold_field_pattern.match(text)
                if match:
                    field, value = match.groups()
                    field = field.strip()
                    value = value.strip()

                    # æ”¯æŒå•è¡Œå¤šä¸ªå­—æ®µï¼ˆé€šè¿‡ | åˆ†éš”ï¼‰
                    segments = [seg.strip() for seg in re.split(r"\|\s*", value) if seg.strip()]
                    if not segments:
                        segments = [value]

                    capturing_summary = False
                    for seg in segments:
                        sub_match = self.bold_field_pattern.match(seg)
                        if sub_match:
                            sub_field, sub_value = sub_match.groups()
                            capturing_summary = self._process_field(
                                meta, sub_field.strip(), sub_value.strip(), summary_lines
                            )
                        else:
                            capturing_summary = self._process_field(
                                meta, field, seg, summary_lines
                            )

                    idx += 1
                    continue

            if capturing_summary:
                if text:
                    summary_lines.append(text)
                idx += 1
                continue

            if not text:
                idx += 1
                continue

            idx += 1

        meta["summary"] = self._normalize_sentence(" ".join(summary_lines))
        meta["next_index"] = idx
        return meta

    def _process_field(self, meta: Dict[str, str], field: str, value: str, summary_lines: List[str]) -> bool:
        """å¤„ç†å•ä¸ªå­—æ®µï¼Œè¿”å›æ˜¯å¦è¿›å…¥æ‘˜è¦é‡‡é›†æ¨¡å¼"""
        normalized_value = self._strip_markdown_links(value)
        field_key = self._normalize_field(field)

        if field in ("ğŸ“ æ‘˜è¦", "æ ¸å¿ƒè§‚ç‚¹"):
            if normalized_value:
                summary_lines.append(normalized_value)
            return True

        if field_key:
            meta[field_key] = normalized_value
        return False

    def _strip_markdown_links(self, text: str) -> str:
        def replace_link(match: re.Match[str]) -> str:
            label, url = match.groups()
            label = label.strip()
            url = url.strip()
            if not label:
                return url
            return f"{label}ï¼ˆé“¾æ¥ï¼š{url}ï¼‰"

        text = re.sub(r"\[([^\]]+)\]\(([^)]+)\)", replace_link, text)
        text = text.replace("**", "").replace("__", "")
        text = text.strip()

        # ç§»é™¤å¤šä½™çš„åˆ†éš”ç¬¦
        text = re.sub(r"\s*\|\s*", "ï¼Œ", text)
        text = re.sub(r"\s+", " ", text)
        return text.strip()

    # ------------------------------------------------------------------ #
    def _normalize_field(self, field: str) -> str:
        mapping = {
            "æ¥æº": "source",
            "å‘å¸ƒ": "published",
            "é“¾æ¥": "link",
        }
        return mapping.get(field, field)

    def _section_key(self, section_name: str) -> str:
        if section_name.startswith("æ·±åº¦æ´å¯Ÿ"):
            return "insights"
        if section_name.startswith("æœ¬å‘¨ç²¾é€‰é¡¹ç›®"):
            return "projects"
        if section_name.startswith("æ¡†æ¶ä¸å·¥å…·æ›´æ–°"):
            return "frameworks"
        if section_name.startswith("æ–°æ¨¡å‹ä¸å¹³å°"):
            return "models"
        if section_name.startswith("å¸‚åœºåŠ¨æ€"):
            return "market"
        return "other"

    def _normalize_title(self, title: str) -> str:
        return title.replace("ğŸ”¥", "").replace("ğŸ“Š", "").replace("ğŸ“ˆ", "").replace("ğŸ”¬", "").replace("ğŸ“š", "").replace("ğŸ› ï¸", "").strip()

    def _normalize_sentence(self, text: str) -> str:
        text = text.replace("**", "").replace("__", "")
        text = re.sub(r"\s+", " ", text)
        return text.strip()



