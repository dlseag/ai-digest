#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•å„ä¸ªé‡‡é›†å™¨
"""

import yaml
import time

def test_hackernews():
    """æµ‹è¯•HackerNewsé‡‡é›†å™¨"""
    print("=" * 60)
    print("æµ‹è¯• Hacker News é‡‡é›†å™¨")
    print("=" * 60)
    
    from src.collectors.hackernews_collector import HackerNewsCollector
    
    start = time.time()
    collector = HackerNewsCollector(
        query_tags=["AI", "LLM"],  # åªæµ‹è¯•2ä¸ªå…³é”®è¯
        min_points=100  # æé«˜é—¨æ§›ï¼Œå‡å°‘æ•°é‡
    )
    items = collector.collect(days_back=3)  # åªé‡‡é›†3å¤©
    elapsed = time.time() - start
    
    print(f"âœ“ é‡‡é›†å®Œæˆ: {len(items)} æ¡ç›®")
    print(f"â±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")
    
    if items:
        print(f"\nç¤ºä¾‹:")
        item = items[0]
        print(f"  æ ‡é¢˜: {item.title}")
        print(f"  ç‚¹æ•°: {item.points}")
    print()


def test_reddit():
    """æµ‹è¯•Reddité‡‡é›†å™¨"""
    print("=" * 60)
    print("æµ‹è¯• Reddit é‡‡é›†å™¨")
    print("=" * 60)
    
    from src.collectors.reddit_collector import RedditCollector
    
    configs = [
        {
            'name': 'r/LocalLLaMA',
            'subreddit': 'LocalLLaMA',
            'category': 'community',
            'priority': 9,
            'limit': 5  # åªé‡‡é›†5ä¸ª
        }
    ]
    
    start = time.time()
    collector = RedditCollector(configs)
    items = collector.collect_all(days_back=3)  # åªé‡‡é›†3å¤©
    elapsed = time.time() - start
    
    print(f"âœ“ é‡‡é›†å®Œæˆ: {len(items)} æ¡ç›®")
    print(f"â±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")
    
    if items:
        print(f"\nç¤ºä¾‹:")
        item = items[0]
        print(f"  æ ‡é¢˜: {item.title}")
        print(f"  çƒ­åº¦: {item.upvotes}åˆ†")
    print()


def test_rss():
    """æµ‹è¯•RSSé‡‡é›†å™¨ï¼ˆåŒ…å«The Batchï¼‰"""
    print("=" * 60)
    print("æµ‹è¯• RSS é‡‡é›†å™¨ï¼ˆåŒ…å«The Batchï¼‰")
    print("=" * 60)
    
    from src.collectors.rss_collector import RSSCollector
    
    # åªæµ‹è¯•The Batch
    sources = [
        {
            'name': 'The Batch (DeepLearning.AI)',
            'url': 'https://www.deeplearning.ai/the-batch/feed/',
            'category': 'newsletter',
            'priority': 9
        }
    ]
    
    start = time.time()
    collector = RSSCollector(sources)
    items = collector.collect_all(days_back=7)
    elapsed = time.time() - start
    
    print(f"âœ“ é‡‡é›†å®Œæˆ: {len(items)} æ¡ç›®")
    print(f"â±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")
    
    if items:
        print(f"\nç¤ºä¾‹:")
        item = items[0]
        print(f"  æ ‡é¢˜: {item.title}")
        print(f"  æ¥æº: {item.source}")
    print()


if __name__ == "__main__":
    print("\nğŸ§ª å¼€å§‹æµ‹è¯•å„ä¸ªé‡‡é›†å™¨\n")
    
    try:
        test_hackernews()
    except Exception as e:
        print(f"âŒ HackerNewsæµ‹è¯•å¤±è´¥: {str(e)}\n")
    
    try:
        test_reddit()
    except Exception as e:
        print(f"âŒ Redditæµ‹è¯•å¤±è´¥: {str(e)}\n")
    
    try:
        test_rss()
    except Exception as e:
        print(f"âŒ RSSæµ‹è¯•å¤±è´¥: {str(e)}\n")
    
    print("=" * 60)
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("=" * 60)

